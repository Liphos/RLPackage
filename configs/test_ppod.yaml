all:
  device: "cuda:0"
main:
  training: True
  training_steps: 50000
env:
  env_name: "CartPole-v1"
  num_agents: 8
replay_buffer:
  max_size: 200
policy:
  algo: "PPODiscrete"
  batch_size: 64
logger:
  logger: "wandb"
  name: "test_ppo_discrete"
